---
{"dg-publish":true,"permalink":"/zotero/articulos/reedha2021/","title":"Vision Transformers For Weeds and Crops Classification Of High Resolution UAV Images","tags":["#zotero"]}
---


<span style="font-variant:small-caps; font-weight: bold;">Vision Transformers For Weeds and Crops Classification Of High Resolution UAV Images</span>

---


> [!multi-column]
>
>> [!example|min-0]+ Autores
>> 
>> **FirstAuthor**:: [[Zotero/Autores/Reedha, Reenul\|Reedha, Reenul]]  
>> **Author**:: [[Dericquebourg, Eric\|Dericquebourg, Eric]]  
>> **Author**:: [[Canals, Raphael\|Canals, Raphael]]  
>> **Author**:: [[Hafiane, Adel\|Hafiane, Adel]]  
 >
>
>> [!info|wide-2]+
>>
>> - **Tipo de fuente**:: journalArticle
>> - **Referencia**:: Reedha R, Dericquebourg E, Canals R & Hafiane A (2021). Vision Transformers For Weeds and Crops Classification Of High Resolution UAV Images.
>> - **DOI**:: 10.48550/ARXIV.2109.02716
>> - **CiteKey**:: reedha2021
>> - **Descripción corta**:: Publisher: arXiv
Version Number: 2
>> - **URL**:: https://arxiv.org/abs/2109.02716
>> - **Zotero Link:** 
>> - [Vision_Transformers_For_Weeds_and_Crops_Classifica.pdf](zotero://select/library/items/IEECJFCF)
>>
>> - **Ver en carpeta**: 
>> - [Vision_Transformers_For_Weeds_and_Crops_Classifica.pdf](file://J:\OneDrive\Articulos\Vision_Transformers_For_Weeds_and_Crops_Classifica.pdf)
>> - **tags**:: #gpt, #Basados, #AnalisisImagen



> [!abstract]+ 
>Crop and weed monitoring is an important challenge for agriculture and food production nowadays. Thanks to recent advances in data acquisition and computation technologies, agriculture is evolving to a more smart and precision farming to meet with the high yield and high quality crop production. Classification and recognition in Unmanned Aerial Vehicles (UAV) images are important phases for crop monitoring. Advances in deep learning models relying on Convolutional Neural Network (CNN) have achieved high performances in image classification in the agricultural domain. Despite the success of this architecture, CNN still faces many challenges such as high computation cost, the need of large labelled datasets, ... Natural language processing's transformer architecture can be an alternative approach to deal with CNN's limitations. Making use of the self-attention paradigm, Vision Transformer (ViT) models can achieve competitive or better results without applying any convolution operations. In this paper, we adopt the self-attention mechanism via the ViT models for plant classification of weeds and crops: red beet, off-type beet (green leaves), parsley and spinach. Our experiments show that with small set of labelled training data, ViT models perform better compared to state-of-the-art CNN-based models EfficientNet and ResNet, with a top accuracy of 99.8\% achieved by the ViT model.


--- 

## Notes

@reedha2021

gpt:: Adopta modelos Vision Transformer para la clasificación de cultivos y malezas en imágenes de UAV, mostrando una alta precisión del 99.8% en comparación con modelos CNN tradicionales ([Reedha et al., 2021](zotero://select/library/items/MVAF5CDH)).






---







