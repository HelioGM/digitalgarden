---
{"dg-publish":true,"permalink":"/zotero/articulos/rai2024/","title":"WeedVision -  A single-stage deep learning architecture to perform weed detection and segmentation using drone-acquired images","tags":["#zotero"]}
---


<span style="font-variant:small-caps; font-weight: bold;">WeedVision -  A single-stage deep learning architecture to perform weed detection and segmentation using drone-acquired images</span>

---


> [!multi-column]
>
>> [!example|min-0]+ Autores
>> 
>> **FirstAuthor**:: [[Zotero/Autores/Rai, Nitin\|Rai, Nitin]]  
>> **Author**:: [[Sun, Xin\|Sun, Xin]]  
 >
>
>> [!info|wide-2]+
>>
>> - **Tipo de fuente**:: journalArticle
>> - **Referencia**:: Rai N & Sun X (2024). WeedVision -  A single-stage deep learning architecture to perform weed detection and segmentation using drone-acquired images. Computers and Electronics in Agriculture **219**, 108792.
>> - **Publicación**:: Computers and Electronics in Agriculture
>> - **DOI**:: 10.1016/j.compag.2024.108792
>> - **CiteKey**:: rai2024
>> - **Nombre corto**:: WeedVision
>> - **URL**:: https://www.sciencedirect.com/science/article/pii/S0168169924001832
>> - **Zotero Link:** 
>> - [WeedVision_Rai_Sun_COMPAG_108792.pdf](zotero://select/library/items/3XSECECK)
>>
>> - **Ver en carpeta**: 
>> - [WeedVision_Rai_Sun_COMPAG_108792.pdf](file://J:\OneDrive\Articulos\WeedVision_Rai_Sun_COMPAG_108792.pdf)
>> - **tags**:: #gpt, #Basados, #DeteccionAutomatica



> [!abstract]+ 
>Deep learning (DL) inspired models have achieved tremendous success in locating target weed species through bounding-box approach (single-stage models) or pixel-wise semantic segmentation (two-stage models), but not both. Therefore, the goal of this research study was to develop a single-stage DL architecture that not only locate weed presence through bounding-boxes but also achieves pixel-wise instance segmentation on unmanned aerial system (UAS) acquired remote sensing images. Moreover, the developed architecture experiments on integrating a novel C3 and C3x module within its backbone for dense feature extraction, as well as ProtoNet (Prototypical network) in its head component for weed masking. Furthermore, the proposed architecture has been trained on five categories of dataset exported using multiple combinations of various dataset augmentation techniques, namely, C1, C2, C3, C4, and C5, for which multiple metrics were assessed on desktop graphical processing unit (GPU) and a palm-sized edge device (AGX Xavier). Results suggest that category C4, a combination of six data augmentation techniques, outperformed the remaining categories by achieving precision scores of 85.4 % (bounding-boxes) and 82.8 % (masking) on a GPU. Whereas, the same model converted to TorchScript was able to achieve 79.1 % and 77 % bounding-box and masking accuracy on an edge device, respectively. The model developed in this research has two potential applications when integrated with site-specific weed management technologies. First, it enables real-time weed detection, allowing for the immediate identification of weeds for spot-spraying applications. Second, it facilitates instance weed masking, aiding in the estimation of weed growth extent in actual field conditions. Moreover, the developed architecture combines both computer vision applications - detection and instance segmentation – to provide comprehensive information about weed growth, eliminating the need for multiple algorithm.


--- 

## Notes

@rai2024

gpt:: Desarrolla WeedVision, una arquitectura de DL de una sola etapa que combina la detección de malezas y la segmentación de instancias en imágenes adquiridas por drones, optimizando la precisión en dispositivos de borde ([Rai y Sun, 2024](zotero://select/library/items/BGEAK2TQ)).






---







