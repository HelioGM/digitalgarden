---
{"dg-publish":true,"permalink":"/zotero/articulos/abdulsalam2023/","title":"A novel UAV-integrated deep network detection and relative position estimation approach for weeds","tags":["#zotero"]}
---


<span style="font-variant:small-caps; font-weight: bold;">A novel UAV-integrated deep network detection and relative position estimation approach for weeds</span>

---


> [!multi-column]
>
>> [!example|min-0]+ Autores
>> 
>> **FirstAuthor**:: [[Zotero/Autores/Abdulsalam, Mahmoud\|Abdulsalam, Mahmoud]]  
>> **Author**:: [[Ahiska, Kenan\|Ahiska, Kenan]]  
>> **Author**:: [[Aouf, Nabil\|Aouf, Nabil]]  
 >
>
>> [!info|wide-2]+
>>
>> - **Tipo de fuente**:: journalArticle
>> - **Referencia**:: Abdulsalam M, Ahiska K & Aouf N (2023). A novel UAV-integrated deep network detection and relative position estimation approach for weeds. Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering 09544100221150284.
>> - **Publicación**:: Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering
>> - **DOI**:: 10.1177/09544100221150284
>> - **CiteKey**:: abdulsalam2023
>> - **Descripción corta**:: Publisher: IMECHE
>> - **URL**:: https://doi.org/10.1177/09544100221150284
>> - **Zotero Link:** 
>> - [Abdulsalam et al_2023_A novel UAV-integrated deep network detection and relative position estimation.pdf](zotero://select/library/items/RMFGYQVN)
>>
>> - **Ver en carpeta**: 
>> - [Abdulsalam et al_2023_A novel UAV-integrated deep network detection and relative position estimation.pdf](file://J:\OneDrive\Articulos\Abdulsalam%20et%20al_2023_A%20novel%20UAV-integrated%20deep%20network%20detection%20and%20relative%20position%20estimation.pdf)
>> - **tags**:: #gpt, #Basados, #DeteccionAutomatica



> [!abstract]+ 
>This paper aims at presenting a novel monocular vision?based approach for drones to detect multiple type of weeds and estimate their positions autonomously for precision agriculture applications. The methodology is based on classifying and detecting the weeds using a proposed deep neural network architecture, named fused-YOLO on the images acquired from a monocular camera mounted on the unmanned aerial vehicle (UAV) following a predefined elliptical trajectory. The detection/classification is complemented by a new estimation scheme adopting unscented Kalman filter (UKF) to estimate the exact location of the weeds. Bounding boxes are assigned to the detected targets (weeds) such that the centre pixels of the bounding box will represent the centre of the target. The centre pixels are extracted and converted into world coordinates forming azimuth and elevation angles from the target to the UAV, and the proposed estimation scheme is used to extract the positions of the weeds. Experiments were conducted both indoor and outdoor to validate this integrated detection/classification/estimation approach. The errors in terms of misclassification and mispositioning of the weeds estimation were minimum, and the convergence of the position estimation results was short taking into account the affordable platform with cheap sensors used in the experiments.


--- 

## Notes

@abdulsalam2023

gpt::  Propuesta de un enfoque basado en visión monocular para drones que detecta y estima la posición de malezas utilizando la arquitectura fused-YOLO y filtros de Kalman ([Abdulsalam et al., 2023](zotero://select/library/items/KJN94TP8)).






---







