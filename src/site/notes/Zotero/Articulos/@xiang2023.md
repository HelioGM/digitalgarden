---
{"dg-publish":true,"permalink":"/zotero/articulos/xiang2023/","title":"CTFuseNet - A Multi-Scale CNN-Transformer Feature Fused Network for Crop Type Segmentation on UAV Remote Sensing Imagery","tags":["#zotero"]}
---


<span style="font-variant:small-caps; font-weight: bold;">CTFuseNet - A Multi-Scale CNN-Transformer Feature Fused Network for Crop Type Segmentation on UAV Remote Sensing Imagery</span>

---


> [!multi-column]
>
>> [!example|min-0]+ Autores
>> 
>> **FirstAuthor**:: [[Zotero/Autores/Xiang, Jianjian\|Xiang, Jianjian]]  
>> **Author**:: [[Liu, Jia\|Liu, Jia]]  
>> **Author**:: [[Chen, Du\|Chen, Du]]  
>> **Author**:: [[Xiong, Qi\|Xiong, Qi]]  
>> **Author**:: [[Deng, Chongjiu\|Deng, Chongjiu]]  
 >
>
>> [!info|wide-2]+
>>
>> - **Tipo de fuente**:: journalArticle
>> - **Referencia**:: Xiang J, Liu J, Chen D, Xiong Q & Deng C (2023). CTFuseNet - A Multi-Scale CNN-Transformer Feature Fused Network for Crop Type Segmentation on UAV Remote Sensing Imagery. Remote Sensing **15**, 1151.
>> - **Publicación**:: Remote Sensing
>> - **DOI**:: 10.3390/rs15041151
>> - **CiteKey**:: xiang2023
>> - **Descripción corta**:: Number: 4
Publisher: Multidisciplinary Digital Publishing Institute
>> - **Nombre corto**:: CTFuseNet
>> - **URL**:: https://www.mdpi.com/2072-4292/15/4/1151
>> - **Zotero Link:** 
>> - [Xiang et al_2023_CTFuseNet.pdf](zotero://select/library/items/DZZB45P8)
>>
>> - **Ver en carpeta**: 
>> - [Xiang et al_2023_CTFuseNet.pdf](file://J:\OneDrive\Articulos\Xiang%20et%20al_2023_CTFuseNet.pdf)
>> - **tags**:: #gpt, #Basados, #AnalisisImagen



> [!abstract]+ 
>Timely and accurate acquisition of crop type information is significant for irrigation scheduling, yield estimation, harvesting arrangement, etc. The unmanned aerial vehicle (UAV) has emerged as an effective way to obtain high resolution remote sensing images for crop type mapping. Convolutional neural network (CNN)-based methods have been widely used to predict crop types according to UAV remote sensing imagery, which has excellent local feature extraction capabilities. However, its receptive field limits the capture of global contextual information. To solve this issue, this study introduced the self-attention-based transformer that obtained long-term feature dependencies of remote sensing imagery as supplementary to local details for accurate crop-type segmentation in UAV remote sensing imagery and proposed an end-to-end CNN–transformer feature-fused network (CTFuseNet). The proposed CTFuseNet first provided a parallel structure of CNN and transformer branches in the encoder to extract both local and global semantic features from the imagery. A new feature-fusion module was designed to flexibly aggregate the multi-scale global and local features from the two branches. Finally, the FPNHead of feature pyramid network served as the decoder for the improved adaptation to the multi-scale fused features and output the crop-type segmentation results. Our comprehensive experiments indicated that the proposed CTFuseNet achieved a higher crop-type-segmentation accuracy, with a mean intersection over union of 85.33% and a pixel accuracy of 92.46% on the benchmark remote sensing dataset and outperformed the state-of-the-art networks, including U-Net, PSPNet, DeepLabV3+, DANet, OCRNet, SETR, and SegFormer. Therefore, the proposed CTFuseNet was beneficial for crop-type segmentation, revealing the advantage of fusing the features found by the CNN and the transformer. Further work is needed to promote accuracy and efficiency of this approach, as well as to assess the model transferability.


--- 

## Notes

@xiang2023

gpt:: Presenta CTFuseNet, una red que combina CNN y Transformer para mejorar la segmentación de tipos de cultivos en imágenes UAV, superando a los modelos de vanguardia como U-Net y SegFormer ([Xiang et al., 2023](zotero://select/library/items/TCXW9TQS)).






---







